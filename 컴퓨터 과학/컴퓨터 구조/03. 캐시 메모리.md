# 캐시 메모리

## 캐시 메모리의 개념
+ 캐시 메모리(Cache Memory)란 컴퓨터의 시스템 성능을 향상시키기 위해 속도가 빠른 장치와 느린 장치 사이에서 속도 차이에 따른 병목현상을 줄이기 위한 범용 메모리이다.
+ 프로세서의 클럭 속도가 빨라짐에 따라 CPU와 주 기억 장치 사이의 속도 차이가 현저하게 증가하였고, 이 때문에 CPU가 아무리 빠르더라도 메인 메모리가 원하는 데이터를 빠르게 제공해 주지 못해 전체 시스템 성능이 증가하기 어렵게 되었다. 이를 병목 현상이라 한다.
+ CPU가 주 기억 장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시 메모리에 저장하고 다음에 이용할 때 주 기억 장치가 아닌 캐시 메모리에서 가져오는 방식으로 속도 향상이 가능하다.
+ CPU 에는 이러한 캐시 메모리가 2 ~ 3개 정도 사용되는데, 이를 L1, L2, L3 캐시 메모리라 한다.    
    - L1 : CPU 내부에 존재한다.
    - L2 : CPU 와 RAM 사이에 존재한다.
    - L3 : 메인보드에 내장되는 경우가 많다.
![image](https://user-images.githubusercontent.com/49611158/145217630-8cfbe6bf-2ae9-4137-a016-fb823502468c.png)

<br>

## Cache Hit & Cache Miss
+ CPU가 필요로 하는 데이터가 캐시 메모리 내에 있으면 'Cache Hit' 이라 하고 캐시 메모리에서 데이터를 가져온다. 캐시 메모리 내에 없다면 'Cache Miss' 라고 한다.
+ 캐시 메모리에 CPU가 원하는 데이터가 존재할 확률을 'Hit Ratio', 적중률이라고 한다. 캐시 메모리의 성능은 적중률에 의해 결정된다.
+ Cache Miss - Compulsory Miss (or Cold Miss)
    - 해당 메모리 주소를 처음 불렀을 때 발생하는 캐시 미스. 프로그램을 새로 실행하는 등의 경우에 발생한다.
    - 데이터를 미리 불러오지 않는 이상 예방하기 힘들지만, 전체 미스에 비하면 발생빈도가 적다.
+ Cache Miss - Conflict Miss
    - 캐시 메모리에 A, B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 발생하는 캐시 미스이다.
    - 아래에서 설명알 Direct Mapped Cache 방식에서 빈번하게 발생한다.
+ Cache Miss - Capacity Miss
    - 캐시 메모리에 공간이 부족해서 나는 캐시 미스. 
    - 캐시 공간이 작아서 벌어지는 경우이므로 캐시 크기를 키우면 되지만, 캐시 크기가 커지면 캐시 접근 속도가 느려지고 파워를 많이 소모하게 된다는 단점이 있다.

<br>

## 캐시 메모리와 지역성(Locality Of Reference)
+ 캐시가 효율적으로 동작하기 위해서는 캐시에 저장할 데이터가 지역성을 가져야 한다.
+ 지역성이란 데이터 접근이 시간적/공간적으로 가깝게 일어나는 것을 의미한다. 이는 프로세스들이 기억 장치 내의 정보를 균일하게 액세스하는 것이 아니라, 어느 순간에 특정 부분을 집중적으로 참조하는 것을 말한다. 
+ 시간적 지역성 (temporal locality of reference)
    - 특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것을 시간적 지역성이라 한다.
    - 시간적 지역성의 대표적인 예시는 반복문(for, while)가 있다.
+ 공간적 지역성 (spatial locality of reference)
    - 특정 데이터에 접근되었을 때, 가까운 주소가 순서대로 접근될 가능성이 높은 것을 공간적 지역성이라고 한다.
    - CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때, 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져온다. 이를 오름차순 접근 시. 이미 저장된 같은 블록의 데이터를 접근하므로 캐시 효율성이 크게 올라간다.
    - 공간적 지역성의 대표적인 예시는 배열이 있다.

<br>

## 캐시 주소 매핑 정책

<br>

![image](https://user-images.githubusercontent.com/49611158/145208107-2dd5266a-093e-4474-986a-00ccfe73a434.png)

+ CPU 는 메모리 주소로 데이터를 받으려 하지만, 이는 가상 메모리 주소이므로 메모리 입장에서는 제대로 인식을 할 수 없다. 
+ 따라서 중간의 메모리 관리 장치(MMU) 가 이를 번역하여 메모리가 인식할 수 있는 형태의 물리 주소로 변환을 한 뒤, 캐시에 해당 주소에 대한 데이터가 존재하는지 확인한다.
+ 이 때 캐시에 저장하는 방식에 따라 물리 주소를 다르게 해석할 수 있다.
+ 기본적으로 캐시에 매핑되는 값은 '인덱스 필드 + 태그 필드 + 데이터 필드' 로 구성된다.

+ 직접 매핑 (Direct Mapping)    
![image](https://user-images.githubusercontent.com/49611158/145208780-8d4d4d58-79c4-443a-85c0-1a9555bd1c00.png)
    - 메모리의 주소 중 뒷 부분은 캐시 메모리 중 어느 블록에 저장할 것인지를 결정한다.
    - 메모리의 주소 중 앞 부분은 캐시 메모리에서 어떠한 데이터를 의미하는지 구분할 때 사용한다. 
    - 주소 중 뒷 부분을 통해 어떤 블록에 데이터가 존재하는지 체크한 뒤, 앞 부분을 통해 해당 데이터가 맞는지 확인하여 해당 값을 그대로 가져올지, 아니면 메인 메모리를 다시 참조할지 결정한다.
    - 매우 단순하고 탐색하기 쉬운 방식이지만, 적중률이 낮다는 단점이 있다.
    - 위 그림에서 '00000' 을 부른 뒤 '00100' 을 부르기 위해서는 첫 번째 블록에 '00000' 대신 '00100'을 다시 적재해야 하기 때문에 Cache Miss 이다.

+ 연관 매핑 (Associative Mapping)
![image](https://user-images.githubusercontent.com/49611158/145210330-8efd7cfd-7acd-4006-91ff-9eb764036f80.png)
    - 캐시에 저장되는 데이터들은 메인 메모리의 순서와는 아무런 관련이 없이 임의로 주소를 저장한다. 즉, 저장하는데에는 별도의 알고리즘이 사용되지 않는다.
    - 하지만 원하는 데이터를 찾기 위해 캐시를 탐색할 때는 모든 블럭을 탐색해야 한다. 이를 위해 병렬 검사를 수행할 수 있는 특수한 캐시를 사용해야하지만, 적중률은 높다.

+ 세트 연관 매핑 (Set Associative Mapping)
![image](https://user-images.githubusercontent.com/49611158/145212208-3c8aacad-6f06-455d-a48b-53b7b541ccf6.png)
    - 직접 매핑과 연관 매핑을 혼합한 방식으로, set 을 먼저 설정한 뒤 어느 블록에 값을 넣을 지 결정한다.
    - 직접 매핑에 비해 검색은 오래 걸리지만, 저장은 빠르다.
    - 연관 매핑에 비해 저장은 느리지만, 검색은 빠르다.


## 캐시 쓰기 정책
+ CPU에서 메모리에 읽기 요청을 하게 되면, 먼저 캐시에 해당 데이터가 존재하는지 확인하고 이를 받으면 된다. 하지만 CPU에서 메모리에 쓰기 요청을 할 경우, 우선 캐시에 저장된 내용을 변경하고 이를 언젠가 메인 메모리에도 반영해야 한다. 이 때 메인 메모리의 내용을 언제 변경할 것인지를 결정하는 정책이다.

+ Write Through 정책    

![image](https://user-images.githubusercontent.com/49611158/145215696-bee55827-966b-4500-9db6-30ad0f5ac2b7.png)    

- CPU 에서 메모리에 쓰기 요청을 할 때 마다 캐시의 내용과 메인 메모리의 내용을 같이 바꾸는 방식이다.
- 구조가 단순하지만 데이터에 대한 쓰기 요청을 할 때 마다 메인 메모리에 접근해야 하므로 캐시에 의한 접근 시간 개선이 없어지므로, 쓰기 요청 시의 접근 시간에서는 전혀 메리트가 없다.
- 하지만 메모리 참조 시 쓰기에 대한 작업은 10 ~ 15%에 불과하므로 메모리와 캐시의 데이터를 동일하게 유지하는 데 별도의 신경을 쓰지 않아도 되어 많이 사용되는 방식이다.

<br>

+ Write Back 정책    

![image](https://user-images.githubusercontent.com/49611158/145216069-c46ca100-2aba-4fb5-8954-f1343d4b0b62.png)    

- CPU 에서 메모리에 대한 쓰기 요청 시, 캐시에서만 쓰기 작업과 그 변경 사실을 확인할 수 있는 표시를 해두고 캐시로부터 해당 블록 내용이 제거될 때 그 블록을 메인 메모리에 복사하여 메인 메모리와 캐시의 내용을 동일하게 유지하는 방식이다.
- 이는 동일한 캐시 블록에 여러 번 쓰기를 실행하는 경우, 캐시만 여러 번 갱신하고 메인 메모리는 한번만 갱신하면 되므로 효율적이다.